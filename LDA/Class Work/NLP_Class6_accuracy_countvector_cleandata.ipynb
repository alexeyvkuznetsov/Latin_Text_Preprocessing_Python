{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Class6_accuracy_countvector_cleandata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu1328/Natural-language-Processing/blob/master/NLP_Class6_accuracy_countvector_cleandata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hCBJBqIWSHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer,TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "import string \n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split as tts,GridSearchCV\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZzdRxYWesz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6775b8eb-2dbd-4c4b-9821-d90a0bd16793"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('words')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOneRwwwWkLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stop_tokenize(Sentence):\n",
        "  word_tokens = word_tokenize(remove_punctuations(Sentence.lower())) \n",
        "    \n",
        "  filtered_sentence = [] \n",
        "  \n",
        "  for w in word_tokens: \n",
        "      if w not in stop_words: \n",
        "          filtered_sentence.append(w) \n",
        "  return filtered_sentence  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_v0IL3hWkOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter=pd.read_csv(\"https://raw.githubusercontent.com/zfz/twitter_corpus/master/full-corpus.csv\")\n",
        "df = pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJhAZ6BWkSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuations(data):\n",
        "  data = data\n",
        "  translator = str.maketrans('', '', '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890')\n",
        "  data = data.translate(translator)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stsLplSHWkVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef5b4b18-e765-43c9-9040-6c191a30c32d"
      },
      "source": [
        "twitter = twitter.head(1000)\n",
        "Sentence = twitter['TweetText'][2]\n",
        "Sentence"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hilarious @youtube video - guy does a duet with @apple 's Siri. Pretty much sums up the love affair! http://t.co/8ExbnQjY\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sQtaQTqWkIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "9b29c333-441c-4ff3-dd12-2e9cbdc45633"
      },
      "source": [
        "sent = stop_tokenize(Sentence)\n",
        "sent"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hilarious',\n",
              " 'youtube',\n",
              " 'video',\n",
              " 'guy',\n",
              " 'duet',\n",
              " 'apple',\n",
              " 'siri',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'sums',\n",
              " 'love',\n",
              " 'affair',\n",
              " 'httptcoexbnqjy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBW0TRlvYDgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lst):\n",
        "  lst = stop_tokenize(lst)        \n",
        "  return ' '.join(lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol4o6CqOYDji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove non english words\n",
        "def remove_non_english(Sentence):\n",
        "\n",
        "  words = set(nltk.corpus.words.words())\n",
        "\n",
        "  sent = Sentence\n",
        "  Clean = \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
        "            if w.lower() in words or not w.isalpha())\n",
        "  return Clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw3K_zB1YDdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter['Clean_tweet'] = twitter['TweetText'].apply(convert)\n",
        "twitter['Clean_tweet'] = twitter['Clean_tweet'].apply(remove_punctuations)\n",
        "twitter['Clean_tweet'] = twitter['Clean_tweet'].apply(remove_non_english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY7xqrjZYQ4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "d25156aa-76f2-43d7-d303-ece3595acbbe"
      },
      "source": [
        "twitter['Clean_tweet']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        apple get crack\n",
              "1                                  apple carrier support\n",
              "2      hilarious video guy duet apple pretty much lov...\n",
              "3                      rim made easy switch apple see ya\n",
              "4                        reason got twitter thanks apple\n",
              "                             ...                        \n",
              "995                      apple upgrade helpful maddening\n",
              "996    hold apple last really like music selection mu...\n",
              "997                 win apple touch get hello world baby\n",
              "998                             poor substitute yo apple\n",
              "999                                       apple scrapple\n",
              "Name: Clean_tweet, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtT0nrKIYRKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3972be59-621c-46ff-a751-a62c0c811544"
      },
      "source": [
        "steps = [('text',CountVectorizer()),('ensemble',RandomForestClassifier())]\n",
        "pipe = Pipeline(steps)\n",
        "twitter.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Topic', 'Sentiment', 'TweetId', 'TweetDate', 'TweetText',\n",
              "       'Clean_tweet'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evnusa-HYQ1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "878cae27-63f9-4d8f-c78e-d531994f80aa"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(twitter['Clean_tweet'])\n",
        "print(vectorizer.get_feature_names())\n",
        "x_train,x_test,y_train,y_test = tts(X,twitter['Sentiment'],test_size=0.3, random_state=30)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ability', 'able', 'absolutely', 'accent', 'access', 'accidently', 'account', 'acquisition', 'across', 'active', 'activity', 'actually', 'add', 'added', 'addicted', 'address', 'admit', 'adobe', 'advance', 'advanced', 'advertise', 'advertising', 'advisor', 'affair', 'afford', 'agree', 'ah', 'ai', 'ailing', 'air', 'airdrop', 'airport', 'aka', 'ala', 'alamo', 'alarm', 'album', 'alcohol', 'alert', 'alive', 'allow', 'ally', 'almost', 'alone', 'already', 'also', 'although', 'alto', 'always', 'amazed', 'amazing', 'amongst', 'amount', 'amused', 'analysis', 'and', 'android', 'angry', 'annoying', 'another', 'answer', 'antitrust', 'anyone', 'anything', 'anyway', 'apologize', 'apology', 'apparently', 'appear', 'apple', 'apply', 'appointment', 'appropriately', 'apt', 'architecture', 'arent', 'argument', 'around', 'arrival', 'arrogant', 'art', 'article', 'artist', 'aside', 'ask', 'ass', 'assistant', 'ate', 'attention', 'audio', 'authorization', 'authorize', 'auto', 'available', 'ave', 'average', 'away', 'awesome', 'awful', 'aye', 'baby', 'back', 'backside', 'backup', 'bad', 'bag', 'bah', 'baked', 'ball', 'ban', 'bar', 'base', 'based', 'battery', 'batting', 'battle', 'beautiful', 'beef', 'bees', 'begging', 'begin', 'beginning', 'behind', 'believe', 'benefit', 'berry', 'best', 'bet', 'beta', 'better', 'beware', 'beyond', 'bidirectional', 'big', 'billion', 'bit', 'bitch', 'bite', 'biz', 'black', 'blackberry', 'blast', 'blaze', 'blend', 'bless', 'blessed', 'bloody', 'blow', 'blue', 'bode', 'body', 'boo', 'book', 'booked', 'booted', 'bottom', 'bought', 'bound', 'bouquet', 'boy', 'brain', 'brand', 'bravo', 'break', 'breaking', 'brick', 'brightness', 'brilliance', 'brilliant', 'bring', 'broke', 'broken', 'brother', 'brought', 'bud', 'buddy', 'bug', 'bummer', 'bump', 'bunch', 'buried', 'burn', 'bus', 'business', 'busy', 'butler', 'buttery', 'button', 'buttons', 'buy', 'buzz', 'cable', 'calendar', 'call', 'calling', 'came', 'camera', 'camper', 'canada', 'cancer', 'canon', 'cant', 'cap', 'car', 'card', 'care', 'careful', 'carrier', 'case', 'cat', 'catastrophically', 'cause', 'center', 'ceremoniously', 'certain', 'champ', 'chance', 'change', 'chaos', 'charge', 'charger', 'charging', 'chat', 'cheap', 'check', 'checked', 'cheer', 'child', 'chips', 'choice', 'choose', 'chrome', 'class', 'click', 'client', 'clock', 'close', 'closed', 'closet', 'cloud', 'cloudy', 'club', 'clue', 'coach', 'cofounder', 'coincidence', 'color', 'come', 'coming', 'community', 'compact', 'company', 'comparison', 'compatible', 'competitive', 'compilation', 'complain', 'complete', 'completely', 'component', 'computer', 'con', 'concrete', 'configure', 'confused', 'connect', 'connection', 'connector', 'consider', 'considered', 'considering', 'consolidation', 'constrained', 'contact', 'content', 'continued', 'continuously', 'contract', 'control', 'convert', 'converting', 'cool', 'cope', 'copy', 'cord', 'corporate', 'correct', 'correction', 'cos', 'cost', 'could', 'couple', 'court', 'covent', 'covered', 'crack', 'cracked', 'cranial', 'crap', 'crash', 'crazy', 'cream', 'create', 'creative', 'credit', 'crome', 'crossed', 'crowd', 'crushed', 'cue', 'curious', 'current', 'currently', 'curse', 'customer', 'cut', 'cute', 'cutting', 'da', 'dad', 'daily', 'damage', 'damn', 'dark', 'data', 'daughter', 'day', 'days', 'de', 'dead', 'deaf', 'deal', 'dealing', 'dear', 'death', 'debut', 'decide', 'declined', 'default', 'define', 'definitely', 'delete', 'deliver', 'denounce', 'dependent', 'design', 'designed', 'developer', 'device', 'dick', 'didnt', 'die', 'difference', 'digital', 'dilation', 'direct', 'dis', 'disabled', 'disagree', 'disappear', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discount', 'discovery', 'dissent', 'dock', 'document', 'documentary', 'dodgy', 'doesnt', 'dogs', 'domain', 'domination', 'donate', 'donated', 'done', 'dont', 'door', 'dope', 'dose', 'doubt', 'downgrade', 'downtown', 'drain', 'drew', 'driving', 'dropping', 'drying', 'dude', 'due', 'duet', 'duff', 'dumb', 'duplication', 'durable', 'dying', 'ear', 'early', 'earnings', 'earth', 'easier', 'easiest', 'easter', 'easy', 'eating', 'edge', 'editor', 'education', 'effort', 'eh', 'either', 'el', 'electric', 'elegance', 'else', 'em', 'employee', 'empty', 'end', 'ending', 'endless', 'enhance', 'enough', 'entering', 'entire', 'entrepreneur', 'equal', 'equipment', 'equivalent', 'eric', 'error', 'escort', 'especially', 'eta', 'eu', 'even', 'evening', 'event', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'evidence', 'evil', 'evolution', 'except', 'exchange', 'excited', 'exclusive', 'exercise', 'exhibit', 'expanded', 'expensive', 'experience', 'explain', 'explaining', 'extend', 'eye', 'eyelash', 'face', 'fact', 'factory', 'fade', 'fail', 'failing', 'fair', 'family', 'fan', 'fantasy', 'far', 'fast', 'faster', 'fault', 'faulty', 'favorite', 'feature', 'featured', 'feeding', 'feel', 'feeling', 'female', 'figure', 'figured', 'file', 'final', 'finally', 'finance', 'financial', 'find', 'fine', 'finger', 'finish', 'first', 'fix', 'fixed', 'fixing', 'flash', 'flat', 'flawless', 'flight', 'focus', 'folder', 'follow', 'following', 'font', 'foolish', 'football', 'force', 'ford', 'forever', 'forget', 'form', 'former', 'forward', 'found', 'founder', 'four', 'free', 'freeze', 'friend', 'front', 'frozen', 'fruit', 'frustration', 'full', 'fully', 'fun', 'function', 'functionality', 'funny', 'future', 'fuzzball', 'gain', 'galaxy', 'game', 'garbage', 'garden', 'gave', 'gay', 'gear', 'gee', 'geek', 'gen', 'generation', 'genius', 'get', 'getting', 'giant', 'gift', 'give', 'giving', 'glad', 'glass', 'global', 'globally', 'go', 'god', 'goes', 'going', 'gon', 'gone', 'good', 'goodwill', 'got', 'governor', 'grandma', 'graphic', 'grass', 'gratis', 'great', 'greatly', 'greedy', 'greener', 'group', 'growth', 'guarantee', 'guess', 'gun', 'guy', 'ha', 'hairline', 'half', 'hall', 'hand', 'handle', 'handled', 'handy', 'hanging', 'happen', 'happening', 'happy', 'hard', 'harder', 'hardware', 'hate', 'hater', 'havent', 'head', 'headline', 'hear', 'hell', 'hello', 'help', 'helpful', 'hero', 'hey', 'hi', 'hide', 'high', 'hilarious', 'hip', 'hire', 'history', 'hit', 'ho', 'hockey', 'hold', 'holder', 'holding', 'home', 'honest', 'hong', 'honor', 'hook', 'hope', 'hopeful', 'hopefully', 'horizontal', 'horse', 'hospital', 'hotel', 'hour', 'household', 'however', 'hubby', 'huge', 'huh', 'humor', 'hungry', 'hurry', 'hut', 'hypo', 'ice', 'icon', 'id', 'identity', 'ie', 'ill', 'image', 'imagine', 'immediate', 'imminent', 'immobile', 'implant', 'implementation', 'importance', 'importantly', 'impossible', 'impressive', 'improve', 'improvement', 'inanimate', 'incapable', 'incase', 'include', 'included', 'incompatible', 'inconvenient', 'increasing', 'incredible', 'indicator', 'inept', 'infamous', 'inferno', 'inform', 'infringement', 'injunction', 'innovation', 'insanely', 'insert', 'insertion', 'insist', 'inspire', 'install', 'instead', 'insurance', 'integrate', 'intellectual', 'intended', 'interconnect', 'interesting', 'internode', 'interrupting', 'intriguing', 'invent', 'invention', 'inventor', 'inventory', 'investigate', 'invisible', 'io', 'iso', 'issue', 'it', 'item', 'jane', 'japan', 'jean', 'jihad', 'job', 'jolly', 'karaoke', 'keep', 'key', 'keyboard', 'keynote', 'kill', 'killing', 'kind', 'knew', 'know', 'knowing', 'known', 'kudos', 'la', 'lack', 'laid', 'lame', 'landscape', 'last', 'late', 'latter', 'launch', 'lawsuit', 'lead', 'leadership', 'leading', 'league', 'learn', 'learned', 'learning', 'least', 'leaving', 'left', 'legacy', 'legal', 'leopard', 'less', 'lesson', 'let', 'life', 'light', 'like', 'likely', 'liking', 'limited', 'line', 'lined', 'link', 'lion', 'list', 'listed', 'listening', 'little', 'live', 'living', 'lo', 'local', 'location', 'lock', 'locked', 'log', 'logged', 'logging', 'login', 'lonely', 'long', 'longer', 'look', 'looking', 'loop', 'loose', 'lose', 'losing', 'loss', 'lost', 'lot', 'love', 'loving', 'lower', 'loyalty', 'luck', 'lunch', 'mac', 'machine', 'mack', 'mad', 'maddening', 'made', 'madness', 'magazine', 'magic', 'magical', 'magically', 'mail', 'main', 'mainly', 'major', 'make', 'making', 'mall', 'man', 'manage', 'management', 'mandarin', 'mansion', 'many', 'map', 'march', 'mark', 'market', 'marketing', 'mary', 'match', 'matter', 'may', 'maybe', 'mean', 'meant', 'media', 'meet', 'meeting', 'memorial', 'memory', 'mention', 'mentor', 'merge', 'message', 'methinks', 'mi', 'middle', 'might', 'mightily', 'mighty', 'migrate', 'million', 'millions', 'min', 'mind', 'mine', 'mines', 'minute', 'misread', 'miss', 'missing', 'mission', 'mo', 'mobile', 'mode', 'model', 'modify', 'moment', 'monopolistic', 'month', 'morning', 'mortar', 'mourning', 'mouse', 'move', 'moving', 'much', 'multiple', 'music', 'must', 'na', 'nam', 'name', 'native', 'nauseous', 'navigate', 'nearest', 'need', 'needless', 'needs', 'negro', 'net', 'network', 'never', 'new', 'newsstand', 'newton', 'next', 'nexus', 'nice', 'night', 'nobody', 'none', 'nonstop', 'nope', 'nostalgia', 'note', 'nothing', 'notification', 'notify', 'nuance', 'nugget', 'number', 'obnoxious', 'obscure', 'obviously', 'occur', 'odd', 'offering', 'office', 'official', 'officially', 'offing', 'often', 'oh', 'old', 'older', 'omission', 'one', 'onto', 'open', 'opening', 'operating', 'opinion', 'opportunity', 'opposite', 'option', 'order', 'ordered', 'organic', 'original', 'os', 'ouch', 'outlook', 'outside', 'overall', 'overbearing', 'overboard', 'overcapacity', 'overhaul', 'owl', 'owner', 'ownership', 'page', 'pain', 'painful', 'painfully', 'painless', 'painted', 'pancreatic', 'para', 'part', 'partner', 'partnership', 'pass', 'passing', 'password', 'past', 'patent', 'patiently', 'pay', 'paying', 'people', 'per', 'perfect', 'perfectly', 'perhaps', 'period', 'perpetual', 'person', 'personal', 'petty', 'phone', 'photo', 'pic', 'pick', 'piece', 'pile', 'pink', 'piracy', 'pith', 'place', 'placement', 'plan', 'planking', 'plate', 'platform', 'play', 'please', 'plus', 'point', 'pointing', 'policy', 'poll', 'pondering', 'poop', 'poor', 'poorly', 'pop', 'popular', 'portion', 'possible', 'possibly', 'post', 'power', 'powered', 'premise', 'preorder', 'present', 'pretty', 'previous', 'price', 'principal', 'printed', 'printer', 'pro', 'problem', 'proceeds', 'process', 'product', 'productivity', 'professional', 'profiting', 'program', 'project', 'promise', 'promising', 'proof', 'proper', 'properly', 'property', 'props', 'protect', 'protection', 'provide', 'proving', 'public', 'publicly', 'puck', 'pull', 'pump', 'pun', 'purchase', 'purely', 'purpose', 'push', 'put', 'python', 'quality', 'quarter', 'question', 'quickly', 'quite', 'racism', 'ram', 'ranch', 'randomly', 'rape', 'rapidly', 'rather', 'ray', 'reaching', 'reaction', 'read', 'reader', 'realize', 'really', 'reason', 'rebuild', 'receipt', 'received', 'recession', 'recognition', 'record', 'recover', 'red', 'regent', 'region', 'registered', 'reinstall', 'relate', 'release', 'relevant', 'reliable', 'remember', 'remind', 'reminder', 'remote', 'removable', 'remove', 'removing', 'rename', 'render', 'renewal', 'rep', 'repair', 'replace', 'replacement', 'reply', 'represent', 'reps', 'request', 'research', 'reservation', 'reserve', 'resilience', 'resolve', 'respect', 'respond', 'response', 'rest', 'restore', 'retail', 'retrieve', 'return', 'reunion', 'revenue', 'review', 'rice', 'right', 'rim', 'ring', 'ringing', 'rip', 'roaring', 'robot', 'roll', 'rolling', 'room', 'rot', 'row', 'rug', 'run', 'running', 'sa', 'sad', 'safari', 'said', 'sale', 'salesperson', 'salute', 'sandwich', 'sarcasm', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'schedule', 'school', 'scrapple', 'screen', 'screw', 'screwed', 'screwing', 'scroll', 'se', 'search', 'searching', 'sec', 'second', 'secret', 'section', 'security', 'see', 'seeing', 'seemingly', 'seen', 'selection', 'self', 'sell', 'selling', 'send', 'sending', 'sense', 'sent', 'sequence', 'seriously', 'server', 'service', 'session', 'set', 'setting', 'settle', 'setup', 'seven', 'shagged', 'share', 'shift', 'ship', 'shoot', 'short', 'show', 'shower', 'showing', 'shrewd', 'shuffle', 'shut', 'sick', 'side', 'sigh', 'sign', 'signal', 'silicon', 'silly', 'silver', 'similar', 'simple', 'simply', 'since', 'sincerely', 'single', 'sinking', 'siris', 'sis', 'sister', 'site', 'sith', 'situation', 'six', 'skin', 'sleep', 'slide', 'slider', 'slinging', 'slipping', 'sloppy', 'slow', 'slowly', 'slows', 'small', 'smart', 'smell', 'snatched', 'snippy', 'snow', 'social', 'soho', 'sold', 'solution', 'solve', 'somehow', 'someone', 'something', 'sometimes', 'song', 'soon', 'sorry', 'sought', 'sound', 'space', 'speak', 'specs', 'speech', 'speed', 'spell', 'spend', 'spending', 'spent', 'spinning', 'spoiled', 'spoke', 'spontaneous', 'spontaneously', 'sports', 'spotted', 'spray', 'sprint', 'sprung', 'squad', 'st', 'stable', 'staff', 'staffed', 'staged', 'stand', 'standing', 'star', 'start', 'state', 'station', 'stay', 'stayed', 'step', 'sticking', 'sticky', 'still', 'stink', 'stock', 'stocks', 'stolen', 'stood', 'stop', 'storage', 'store', 'story', 'straight', 'strange', 'strategy', 'street', 'struggling', 'stuck', 'student', 'stuff', 'stupid', 'style', 'stylus', 'subscribe', 'substitute', 'succeed', 'success', 'suck', 'sucking', 'sudden', 'suddenly', 'suffering', 'suing', 'suit', 'summer', 'support', 'sure', 'surely', 'survey', 'surviving', 'swallow', 'sweet', 'switch', 'switcher', 'symbol', 'sync', 'system', 'ta', 'tab', 'tablet', 'take', 'taken', 'taking', 'talk', 'talking', 'tax', 'team', 'tear', 'tech', 'technology', 'techy', 'telegraph', 'tell', 'terminal', 'terrible', 'test', 'testing', 'text', 'th', 'thank', 'thankful', 'thankfully', 'thanks', 'thats', 'thee', 'theft', 'theres', 'theyre', 'thing', 'think', 'thinking', 'tho', 'thorn', 'thorough', 'though', 'thought', 'throat', 'throne', 'throw', 'thunderbird', 'thunderbolt', 'thus', 'tie', 'tiger', 'tighten', 'til', 'till', 'time', 'timed', 'times', 'timing', 'tint', 'tired', 'titanic', 'title', 'today', 'together', 'toggle', 'told', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'top', 'tossing', 'total', 'totally', 'touch', 'towards', 'traffic', 'tragic', 'training', 'translator', 'trash', 'tribute', 'trick', 'tried', 'trip', 'triple', 'trouble', 'troublemaker', 'true', 'truly', 'try', 'trying', 'tube', 'turn', 'turned', 'turning', 'turns', 'tweet', 'twit', 'twitter', 'two', 'type', 'ugh', 'um', 'umber', 'unauthorized', 'unbelievable', 'unconventional', 'undo', 'unexpected', 'unhappy', 'unique', 'unladen', 'unless', 'unlocked', 'unlocking', 'unquality', 'unreal', 'unveiled', 'unwanted', 'upcoming', 'update', 'upgrade', 'upset', 'upstairs', 'ur', 'us', 'usable', 'usage', 'use', 'used', 'useful', 'useless', 'user', 'utility', 'utter', 'utterly', 'valley', 'valuable', 'verge', 'version', 'vertical', 'via', 'vibrate', 'vibrating', 'video', 'vie', 'virtual', 'visit', 'visual', 'voice', 'volume', 'wack', 'wait', 'waiting', 'walk', 'wall', 'walled', 'wan', 'want', 'war', 'warm', 'warning', 'warranty', 'wash', 'wasnt', 'wasted', 'wasting', 'watch', 'watched', 'watching', 'way', 'weather', 'web', 'week', 'weekend', 'weekly', 'weird', 'welcome', 'well', 'wen', 'went', 'werent', 'west', 'whats', 'wheel', 'white', 'whoa', 'whoever', 'whole', 'whoops', 'wid', 'wife', 'win', 'winning', 'wireless', 'wise', 'wish', 'wished', 'wit', 'witchcraft', 'within', 'without', 'woke', 'wonder', 'wonky', 'wont', 'word', 'work', 'worked', 'working', 'works', 'workshop', 'world', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'wow', 'write', 'wrong', 'ya', 'yahoo', 'yapping', 'yea', 'yeah', 'year', 'yellow', 'yelp', 'yes', 'yesterday', 'yet', 'yo', 'young', 'youve', 'yr', 'zero']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRh41mNYjSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = pd.DataFrame(x_train.toarray(),columns=vectorizer.get_feature_names())\n",
        "x_test = pd.DataFrame(x_test.toarray(),columns=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxFczAnlYjZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Apply RandomForestClassifier and LightGBM\n",
        "##write a report on the classification report :Precision,Recall,Accuracy note \n",
        "##change cut off and do the same:0.7,0.8,0.6\n",
        "##And write  note on how precision recall and accuarcy change with the change in threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_gfj1OeYxH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " rf = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnt9Ta2OYxLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'max_depth': [10, 20, 30, None],\n",
        " 'max_features': ['sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 5, 10],\n",
        " 'n_estimators': range(10,50,10)}\n",
        " \n",
        "gs_rf = GridSearchCV(estimator = rf, param_grid = params, \n",
        "                          cv = 5, n_jobs = 10, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzM8YKDuYxFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "510cf350-6c7c-494c-e595-abb450793949"
      },
      "source": [
        "gs_rf.fit(x_train,y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   20.2s\n",
            "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   40.8s\n",
            "[Parallel(n_jobs=10)]: Done 720 out of 720 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators='warn', n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='warn', n_jobs=10,\n",
              "             param_grid={'max_depth': [10, 20, 30, None],\n",
              "                         'max_features': ['sqrt'],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': range(10, 50, 10)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lBXZe95YjXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a28aa033-9437-4a37-d9fc-971f1ce10f58"
      },
      "source": [
        "print(classification_report(gs_rf.predict(x_test),y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.49      0.53       103\n",
            "     neutral       0.73      0.67      0.70       178\n",
            "    positive       0.29      0.74      0.42        19\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.53      0.63      0.55       300\n",
            "weighted avg       0.65      0.61      0.62       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCpu87qaA3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Precision and recall of this model is respectable for neutral but bad on positive and negative meaning the model is able to decently predict if a twee is neutral or not but not able to predict the postivity or the negativity of the tweet.\n",
        "##Accuracy is bad but to increase the accuracy the model overfits on the training data giving worse accuracy on the test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79VIk6wAaA-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2f0a6200-35cb-496a-a1e8-971d923824de"
      },
      "source": [
        "!pip install lightgbm\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBAildNBaK95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    \"objective\" : \"multiclass\",\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class':3,\n",
        "    'learning_rate':0.01,\n",
        "    'max_depth': 7,\n",
        "    'num_leaves': 127,\n",
        "    'feature_fraction': 0.4,\n",
        "    'bagging_freq': 10,\n",
        "    'num_iterations':1000 ,\n",
        "    'max_bin' : 32}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExO8-1lEaOUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()  \n",
        "d_train = lgb.Dataset(x_train,le.fit_transform(y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf8XB9noaOab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "de4fb3ae-548c-4559-f645-45072f428126"
      },
      "source": [
        "clf = lgb.train( params,d_train, 100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoSaq-e5aVeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "preds = clf.predict(x_test)\n",
        "best_preds= [np.argmax(line) for line in preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Ra0QmIaVqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c345201a-99d0-42ad-d3a8-cda4c0e33b95"
      },
      "source": [
        "np.bincount((le.fit_transform(y_train)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([229, 355, 116])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOrh_5ClaZRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "76908735-3416-40ba-8f2d-170fdb7e0e89"
      },
      "source": [
        "print(classification_report(le.inverse_transform(best_preds),y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.14      0.39      0.20        31\n",
            "     neutral       0.90      0.57      0.70       258\n",
            "    positive       0.15      0.64      0.24        11\n",
            "\n",
            "    accuracy                           0.56       300\n",
            "   macro avg       0.39      0.53      0.38       300\n",
            "weighted avg       0.79      0.56      0.63       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMZ-2uqXaZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##The precision of neutral class is high meaning our model mostly classifies the data that it captures correctly on being neutral or not but the other 2 are bad since our model cant classify it well even after hyperparameter tuning\n",
        "##Accuracy is bad but to increase the accuracy the model overfits on the training data giving worse accuracy on the test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csBBQmCialaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "835d3b29-6e1e-4a7e-a819-9ad8041bff82"
      },
      "source": [
        "np.bincount((best_preds))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 31, 258,  11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twjuSrCTalhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "95c19429-358f-4e87-ccf1-5f7802a9839d"
      },
      "source": [
        "import numpy as np\n",
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(classification_report(le.inverse_transform(best_preds_train),y_train))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kONC13rauYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "78af2144-794f-442c-e348-af80f7ac8876"
      },
      "source": [
        "###for lgbm\n",
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_1(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.6:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.6 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_1(preds)),y_train))\n",
        "      \n",
        "###For rf\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_1(pred_rf)),y_test) )\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.6 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.15      0.77      0.25        44\n",
            "     neutral       0.37      0.73      0.50       181\n",
            "    positive       0.81      0.20      0.32       475\n",
            "\n",
            "    accuracy                           0.37       700\n",
            "   macro avg       0.44      0.57      0.35       700\n",
            "weighted avg       0.66      0.37      0.36       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.49      0.53       103\n",
            "     neutral       0.73      0.67      0.70       178\n",
            "    positive       0.29      0.74      0.42        19\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.53      0.63      0.55       300\n",
            "weighted avg       0.65      0.61      0.62       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.28      0.71      0.40        34\n",
            "     neutral       0.49      0.77      0.60       105\n",
            "    positive       0.77      0.23      0.35       161\n",
            "\n",
            "    accuracy                           0.47       300\n",
            "   macro avg       0.51      0.57      0.45       300\n",
            "weighted avg       0.62      0.47      0.44       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2m0vEHTaui1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for rf model\n",
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for lgbm model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPnrhRGvautJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "970434a7-b131-4b8b-b7c2-686756cea308"
      },
      "source": [
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_2(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.7:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.7 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_2(preds)),y_train))\n",
        "###For rf\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_2(pred_rf)),y_test) )\n",
        "      \n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.7 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.09      0.80      0.16        25\n",
            "     neutral       0.08      0.72      0.14        39\n",
            "    positive       0.95      0.17      0.29       636\n",
            "\n",
            "    accuracy                           0.23       700\n",
            "   macro avg       0.37      0.56      0.20       700\n",
            "weighted avg       0.87      0.23      0.28       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.49      0.53       103\n",
            "     neutral       0.73      0.67      0.70       178\n",
            "    positive       0.29      0.74      0.42        19\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.53      0.63      0.55       300\n",
            "weighted avg       0.65      0.61      0.62       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.16      0.78      0.27        18\n",
            "     neutral       0.42      0.81      0.55        85\n",
            "    positive       0.88      0.21      0.34       197\n",
            "\n",
            "    accuracy                           0.42       300\n",
            "   macro avg       0.48      0.60      0.39       300\n",
            "weighted avg       0.70      0.42      0.40       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBZJA3wbJYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for rf model\n",
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for lgbm model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlCmacnzbJhh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "e2cc896a-f7f9-420b-d6ec-2ae3f624f76f"
      },
      "source": [
        "preds = clf.predict(x_train)\n",
        "best_preds_train= [np.argmax(line) for line in preds]\n",
        "print(\"Default Threshold for lgbm : \\n\",classification_report(le.inverse_transform(best_preds_train),y_train))\n",
        "def thresh_3(array):\n",
        "  a = []\n",
        "  for i in range(len(array)):\n",
        "    if max(array[i])>0.8:\n",
        "      a.append(np.argmax(array[i]))\n",
        "    else:\n",
        "      a.append(2)\n",
        "  return a\n",
        "print(\"\\n 0.8 Threshold for lgbm : \\n\",classification_report(le.inverse_transform(thresh_3(preds)),y_train))\n",
        "      \n",
        "###For rf\n",
        "pred_rf = gs_rf.predict_proba(x_test)\n",
        "print(\"Default Threshold for rf : \\n\",(classification_report(gs_rf.predict(x_test),y_test)))\n",
        "print(\"\\n 0.6 threshold for rf : \\n\",classification_report(le.inverse_transform(thresh_3(pred_rf)),y_test) )\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.65      0.40       101\n",
            "     neutral       0.93      0.57      0.70       582\n",
            "    positive       0.09      0.65      0.17        17\n",
            "\n",
            "    accuracy                           0.58       700\n",
            "   macro avg       0.44      0.62      0.42       700\n",
            "weighted avg       0.81      0.58      0.65       700\n",
            "\n",
            "\n",
            " 0.8 Threshold for lgbm : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.03      1.00      0.05         6\n",
            "     neutral       0.03      1.00      0.07        12\n",
            "    positive       1.00      0.17      0.29       682\n",
            "\n",
            "    accuracy                           0.19       700\n",
            "   macro avg       0.35      0.72      0.14       700\n",
            "weighted avg       0.98      0.19      0.28       700\n",
            "\n",
            "Default Threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.49      0.53       103\n",
            "     neutral       0.73      0.67      0.70       178\n",
            "    positive       0.29      0.74      0.42        19\n",
            "\n",
            "    accuracy                           0.61       300\n",
            "   macro avg       0.53      0.63      0.55       300\n",
            "weighted avg       0.65      0.61      0.62       300\n",
            "\n",
            "\n",
            " 0.6 threshold for rf : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.05      1.00      0.09         4\n",
            "     neutral       0.29      0.84      0.43        57\n",
            "    positive       0.98      0.20      0.33       239\n",
            "\n",
            "    accuracy                           0.33       300\n",
            "   macro avg       0.44      0.68      0.28       300\n",
            "weighted avg       0.84      0.33      0.34       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcbM-ROdbVYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for rf model\n",
        "\n",
        "##We see that increasing the threshold increases the recall of the negative and neutral classes but reduces the precision across all the classes for lgbm model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZm82EredRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
